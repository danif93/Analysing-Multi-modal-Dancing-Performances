{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import CV_utils as cvu\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_b_frames, l_bgs_frames, l_c_frames, l_gs_frames = cvu.read_frames('Video/representative/Lightness/Video attached to the ICMI 2017 Paper - Lightness.mp4')\n",
    "f_b_frames, f_bgs_frames, f_c_frames, f_gs_frames = cvu.read_frames('Video/representative/Fragility/Video attached to the ICMI 2017 Paper - Fragility.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADIENT DIFFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHARED FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection of the gradient along the most significant (fundamental) direction\n",
    "def compute_proj(g_x, g_y):\n",
    "    \n",
    "    proj_counter = np.zeros((cvu.len_ref_angles))\n",
    "    \n",
    "    for h in range(cvu.len_ref_angles//2):\n",
    "\n",
    "        # project\n",
    "        proj_counter[h] = np.dot([g_x, g_y], cvu.ref_angles[h])\n",
    "\n",
    "        # if negative it's the origin-symmetric angle\n",
    "        if proj_counter[h] < 0:\n",
    "            proj_counter[h+(cvu.len_ref_angles//2)] -= proj_counter[h]\n",
    "            proj_counter[h] = 0\n",
    "\n",
    "    #to zero all the projections but the maximum one -- clustering    \n",
    "    max_index = np.argmax(proj_counter)\n",
    "    proj_counter[[idx for idx in range(cvu.len_ref_angles) if idx!=max_index]] = 0\n",
    "    \n",
    "    return proj_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the gradient for each patch with Sobel\n",
    "# compute the mean of such gradients in both the directions\n",
    "# project such mean gradient\n",
    "\n",
    "def compute_grad_v2(patch_mat, size=3):\n",
    "    \n",
    "    proj_mat = np.zeros((patch_mat.shape[0], patch_mat.shape[1], cvu.len_ref_angles))\n",
    "    \n",
    "    for i, patch_line in enumerate(patch_mat):\n",
    "        for j, patch in enumerate(patch_line):\n",
    "            \n",
    "            # gradient computation of a patch\n",
    "            sobelx64f = cv2.Sobel(patch, cv2.CV_64F,1,0,ksize=size)\n",
    "            abs_sobel64f = np.absolute(sobelx64f)\n",
    "            grad_x = np.uint8(abs_sobel64f)\n",
    "\n",
    "            sobely64f = cv2.Sobel(patch, cv2.CV_64F,0,1,ksize=size)\n",
    "            abs_sobel64f = np.absolute(sobely64f)\n",
    "            grad_y = np.uint8(abs_sobel64f)\n",
    "            \n",
    "            # projection of the mean gradient\n",
    "            proj_mat[i,j,:] = compute_proj(np.mean(grad_x), np.mean(grad_y))\n",
    "    \n",
    "    return proj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling of neighbour gradient patches\n",
    "def zoom_out_v2(grads, n_patch): # n_patch tuple (num_patch_y, num_patch_x)\n",
    "    \n",
    "    if n_patch[0]%2 == 0 or n_patch[1]%2 == 0:\n",
    "        raise Exception(\"n_patch must be a touple of odd numbers\")\n",
    "    \n",
    "    frames_pools = []\n",
    "    tmp_y = n_patch[0]//2\n",
    "    tmp_x = n_patch[1]//2\n",
    "    \n",
    "    len_x = grads[0].shape[1]//tmp_x\n",
    "    len_y = grads[0].shape[0]//tmp_y\n",
    "    \n",
    "    for frame_grad in grads:\n",
    "        \n",
    "        pools = np.zeros((n_patch[0], n_patch[1], frame_grad.shape[2]))\n",
    "        \n",
    "        for x in range(tmp_x):\n",
    "            for y in range(tmp_y):\n",
    "                \n",
    "                pools[x, y, :] = sum(sum(frame_grad[x*len_x:(x+1)*len_x, y*len_y:(y+1)*len_y]))\n",
    "                \n",
    "                if x != tmp_x-1:\n",
    "                    \n",
    "                    pools[x, y, :] = sum(sum(frame_grad[int((x+0.5)*len_x):int((x+1.5)*len_x), y*len_y:(y+1)*len_y]))\n",
    "                    \n",
    "                    if y != tmp_y-1:\n",
    "                        \n",
    "                        #pools[x, y, :] = sum(sum(frame_grad[int((x+0.5)*len_x):int((x+1.5)*len_x),int((y+0.5)*len_y):int((y+1.5)*len_y)]))\n",
    "                        pools[x, y, :] = sum(sum(frame_grad[x*len_x:(x+1)*len_x, int((y+0.5)*len_y):int((y+1.5)*len_y)]))\n",
    "                \n",
    "                elif y != tmp_y-1:\n",
    "                    \n",
    "                    pools[x, y, :] = sum(sum(frame_grad[x*len_x:(x+1)*len_x, int((y+0.5)*len_y):int((y+1.5)*len_y)]))         \n",
    "            \n",
    "        # TODO threshold 80%?\n",
    "        \n",
    "        frames_pools.append(pools.reshape(-1, pools.shape[2]))\n",
    "        \n",
    "    return frames_pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to divide an image in patches\n",
    "def extract_patches(img, patch_size, overlap):\n",
    "    \n",
    "    img_shape = img.shape\n",
    "    \n",
    "    # compare img size with patch size\n",
    "    if img_shape[0] < patch_size or img_shape[1] < patch_size:\n",
    "        raise Exception(\"Patch size too big. Image shape {}, patch size ({}, {})\".format(img_shape, patch_size, patch_size))\n",
    "    \n",
    "    # how many patches can fit the img height\n",
    "    shape_x = ((img_shape[0]-patch_size)//(patch_size-overlap))+1\n",
    "    \n",
    "    # if img height is not a multiple of patch_size the last one will be adjusted in some way...\n",
    "    if (img_shape[0]-patch_size)%(patch_size-overlap) != 0:     \n",
    "        shape_x += 1\n",
    "     \n",
    "    # how many patches can fit the img length    \n",
    "    shape_y = ((img_shape[1]-patch_size)//(patch_size-overlap))+1\n",
    "    \n",
    "    # if img length is not a multiple of patch_size the last one will be adjusted in some way...\n",
    "    if (img_shape[1]-patch_size)%(patch_size-overlap) != 0:     \n",
    "        shape_y += 1\n",
    "    \n",
    "    # pixels in a patch, the first two values are for patch indexing and the latter ones are the actual img portion:\n",
    "    # [patch_over_height * patch_over_length * pixel_height * pixel_length]\n",
    "    patches = np.zeros((shape_x, shape_y, patch_size, patch_size))\n",
    "    \n",
    "    h = 0\n",
    "                        \n",
    "    for i in range(shape_x):\n",
    "        l = 0\n",
    "\n",
    "        for j in range(shape_y):            \n",
    "            # if it's the last patch along the height...\n",
    "            if i == shape_x-1:\n",
    "                # ... and the last one along the length\n",
    "                if j == shape_y-1:\n",
    "                    tmp = np.vstack((img[h:, l:], np.zeros((patch_size-(img.shape[0]-h), img.shape[1]-l))))\n",
    "                    tmp = np.hstack((tmp, np.zeros((patch_size, patch_size-(img.shape[1]-l)))))\n",
    "                    patches[i, j, :, :] = tmp\n",
    "\n",
    "                else:\n",
    "                    patches[i, j, :, :] = np.vstack((img[h:, l:l+patch_size], np.zeros((patch_size-(img.shape[0]-h),patch_size))))\n",
    "\n",
    "                    \n",
    "            # if it's just the last patch along the length        \n",
    "            elif j == shape_y-1:\n",
    "                patches[i, j, :, :] = np.hstack((img[h:h+patch_size, l:], np.zeros((patch_size, patch_size-(img.shape[1]-l)))))\n",
    "            \n",
    "            else:\n",
    "                patches[i, j, :, :] = img[h:h+patch_size, l:l+patch_size]\n",
    "            \n",
    "            l += patch_size-overlap\n",
    "        h += patch_size-overlap            \n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the difference of the gradient value\n",
    "#in each fundamental direction in each pool between two consecutive frames\n",
    "\n",
    "#Moreover it calls the functions to compute the gradients\n",
    "#and the pools\n",
    "def compute_diff(frames, size, overlap, n_skip, pools):\n",
    "    \n",
    "    grads = []\n",
    "    diff = []\n",
    "    \n",
    "    s = 0\n",
    "        \n",
    "    print(\"\\tcalculating the gradient of frames...\")\n",
    "    \n",
    "    for frame in frames:\n",
    "        \n",
    "        if s != 0 and s<= skip:\n",
    "            s += 1\n",
    "            continue\n",
    "            \n",
    "        patches = extract_patches(frame, size, overlap)\n",
    "        \n",
    "        grads.append(compute_grad_v2(patches))\n",
    "        \n",
    "        s = 0\n",
    "    \n",
    "    print(\"\\tpooling the frames...\")\n",
    "    \n",
    "    frames_pools = zoom_out_v2(grads, pools)\n",
    "    \n",
    "    print(\"\\tcalculating the gradients variation...\")\n",
    "    \n",
    "    #print(frames_pools)\n",
    "    \n",
    "    for i, pools in enumerate(frames_pools[:-1]):\n",
    "        \n",
    "        next_pools = frames_pools[i+1]\n",
    "        diff.append(next_pools-pools)\n",
    "        \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOURIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_dataset_creation(video_frames_list, size=40, overlap=1, n_skip=0, pools=(5,3), verbose=False):\n",
    "    \n",
    "    angles_transformed_list = []\n",
    "    \n",
    "    for i, video_frames in enumerate(video_frames_list):\n",
    "        if verbose:\n",
    "            tot = len(video_frames_list)\n",
    "            print('\\nWorking on video {}/{}'.format(i+1, tot))\n",
    "            print('\\t.... Computing the gradient difference frame by frame')\n",
    "            start = time.time()\n",
    "\n",
    "        diff = compute_diff(video_frames, size, overlap, n_skip, pools)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\t.... complete. Time spent %s\" % (time.time()-start))\n",
    "            \n",
    "        # n_pools * n_angles * n_frames-1 = n_diff\n",
    "        angles_signal = np.zeros((diff[0].shape[0], diff[0].shape[1], len(diff)))\n",
    "        \n",
    "        for j, d in enumerate(diff): angles_signal[:,:,j] = d\n",
    "        \n",
    "        angles_transformed = np.zeros((angles_signal.shape[0],angles_signal.shape[1], int(np.ceil((angles_signal.shape[2]+1)/2)*2)))\n",
    "        \n",
    "        if verbose:\n",
    "            start = time.time()\n",
    "            print('\\tComputing the Fourier serie...')\n",
    "            \n",
    "        for h, pool_angles in enumerate(angles_signal):\n",
    "            for j, angle_signal in enumerate(pool_angles):\n",
    "                # call the fourier transformation on angle_signal\n",
    "                coeff = np.fft.rfft(angle_signal)\n",
    "                angles_transformed[h, j, :] = np.hstack((coeff.real, coeff.imag))\n",
    "                \n",
    "            \n",
    "        if verbose: print('\\t.... complete. Time spent: %s'%(time.time()-start))\n",
    "        \n",
    "        #flattening of the transformation matrix\n",
    "        angles_transformed_list.append(angles_transformed.reshape(-1, angles_transformed.shape[2]).reshape(-1))\n",
    "        \n",
    "    return np.asmatrix(angles_transformed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the data and create the dataset using fourier\n",
    "def load_gradient(path_to_read_binary, path_to_read_density, path_to_write, width, verbose=False):\n",
    "\n",
    "    indexes_deleted = []\n",
    "\n",
    "    # Batch video loading (10*15)\n",
    "    for j in range(1,16):\n",
    "\n",
    "        if verbose: print(\"\\nExtracting data for the videos from {} to {}\".format((j-1)*10+1, j*10))\n",
    "        \n",
    "        video_list = cvu.binary_read(path_to_read_binary, j)\n",
    "        \n",
    "        pd_density_frames = pd.read_pickle(path_to_read_density+str(j)+'.pkl')\n",
    "        \n",
    "        X, indexes = cvu.normalize_preprocessing(video_list, pd_density_frames, width=width, verbose=verbose)\n",
    "        \n",
    "        # invoke the creation of the dataset by fourier\n",
    "        X = fourier_dataset_creation(X, verbose=verbose)\n",
    "        \n",
    "        bDel_indexes = [x+(j-1)*10 for x in indexes]\n",
    "        indexes_deleted += bDel_indexes\n",
    "        \n",
    "        df = pd.DataFrame(X)\n",
    "        df.to_csv(path_to_write+str(j)+\".csv\", index=False)\n",
    "        \n",
    "    return indexes_deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_deleted = load_gradient('Video/binary_video/','Video/densityFrame_pkl/videos_density_', 'datasets/fourier_gradient_partial/fourier_gradient_dataset_', 650, verbose=True)\n",
    "\n",
    "pd.DataFrame(indexes_deleted).to_csv('datasets/fourier_gradient_partial/fourier_gradient_indexes_deleted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvu.merge_dataset('datasets/fourier_gradient_partial/fourier_gradient_dataset_', 'datasets/fourier_gradient_dataset.csv', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVG OF SQUARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of matrices of difference, it returns the mean of the squares of such element, grouped by batch_size\n",
    "def avg_squared_pools_channels(diff_list, batch_size=0, n_overlap=0, n_skip=0):\n",
    "    \n",
    "    if batch_size == 0 : batch_size=len(diff_list)\n",
    "    \n",
    "    batch_list = []\n",
    "    batch = np.zeros(diff_list[0].shape)\n",
    "    overlap_diff = np.zeros(diff_list[0].shape)\n",
    "    skip = 0 # consecutive frames skip counter\n",
    "    i = 0    # seen frames counter (used for the overlapping purpose)\n",
    "    \n",
    "    for diff in diff_list:\n",
    "        \n",
    "        # skip consecutive frames, pick one every n_skip\n",
    "        if skip != 0 and skip <= n_skip:\n",
    "            skip += 1\n",
    "            continue\n",
    "        else:\n",
    "            skip = 0\n",
    "            \n",
    "        diff = np.square(diff)\n",
    "            \n",
    "        if i >= batch_size-n_overlap:           \n",
    "            overlap_diff += diff\n",
    "            \n",
    "        batch += diff\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        # if it has already seen batch_size imgs\n",
    "        if i%batch_size == 0:\n",
    "            \n",
    "            batch_list.append(batch)\n",
    "            batch = n_overlap # start from the stored frames\n",
    "            \n",
    "            i = n_overlap\n",
    "            overlap_frames = np.zeros(diff.shape)\n",
    "        \n",
    "        skip += 1\n",
    "        \n",
    "    return sum(batch_list)/len(batch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_squared_gradient_dataset_creation(video_frames_list, size=40, overlap=1, n_skip=0, pools=(5,3), verbose=False):\n",
    "    \n",
    "    pools_channels_in_time_list = []\n",
    "    \n",
    "    if verbose: tot = len(video_frames_list)\n",
    "       \n",
    "    for i, video_frames in enumerate(video_frames_list):\n",
    "                \n",
    "        if verbose:\n",
    "            print('\\nWorking on video {}/{}'.format(i+1, tot))\n",
    "            print('\\t.... Computing the gradient difference frame by frame')\n",
    "            start = time.time()\n",
    "\n",
    "        diff = compute_diff(video_frames, size, overlap, n_skip, pools)\n",
    "    \n",
    "        if verbose:\n",
    "            print(\"\\t.... Complete. Time spent %s\" % (time.time()-start))\n",
    "            print(\"\\t.... Computing avg squared\")\n",
    "            start = time.time()\n",
    "    \n",
    "        n_frames = len(diff)\n",
    "    \n",
    "        #TODO add a for that perform different approaches like in density\n",
    "        # if verbose print approach number\n",
    "        pools_channels_in_time = np.zeros((diff[0].shape))\n",
    "            \n",
    "        pools_channels_in_time = avg_squared_pools_channels(diff)\n",
    "        \n",
    "        if verbose: print(\"\\t.... Complete. Time spent %s\" % (time.time()-start))\n",
    "    \n",
    "        pools_channels_in_time_list.append(pools_channels_in_time.reshape(-1))\n",
    "    \n",
    "    return np.asmatrix(pools_channels_in_time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the data and create the dataset using the avg of the squares\n",
    "def load_avgSquared_gradient(path_to_read_binary, path_to_read_density, path_to_write, width, \n",
    "                                        size=40, n_skip=3, pool_size=(5,3), verbose = False):\n",
    "\n",
    "    indexes_deleted = []\n",
    "\n",
    "    # Batch video loading (10*15)\n",
    "    for j in range(1,16):\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\nExtracting data for the videos from {} to {}\".format((j-1)*10+1, j*10))\n",
    "        \n",
    "        video_frames_list = cvu.binary_read(path_to_read_binary, j, verbose=verbose)\n",
    "        \n",
    "        pd_density_frames = pd.read_pickle(path_to_read_density+str(j)+'.pkl')\n",
    "        \n",
    "        X, _ = cvu.normalize_preprocessing(video_frames_list, pd_density_frames, width, n_frames=None, verbose=verbose)\n",
    "        \n",
    "        X = avg_squared_gradient_dataset_creation(X, size, n_skip, pool_size, verbose=verbose)\n",
    "        \n",
    "        df = pd.DataFrame(X)\n",
    "        \n",
    "        df.to_csv(path_to_write+str(j)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_avgSquared_gradient('Video/binary_video/', 'Video/densityFrame_pkl/videos_density_', 'datasets/avg_gradient_partial/avg_square_grad_', 650, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvu.merge_dataset('datasets/avg_gradient_partial/avg_square_grad_', 'datasets/avg_square_grad.csv', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOURIER TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('datasets/fourier_gradient_dataset.csv').as_matrix()\n",
    "iDel = pd.read_csv('datasets/fourier_gradient_partial/fourier_gradient_indexes_deleted.csv', index_col=0).values.flatten()\n",
    "y = cvu.load_marks()[1].values\n",
    "y = np.delete(y, iDel, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reordering\n",
    "\n",
    "X_new = np.zeros(X.shape)\n",
    "\n",
    "for mul in range(0, 15*8):\n",
    "    for base in range(250):\n",
    "        X_new[:, base+mul*250] = X[:, base+mul*500]\n",
    "        X_new[:, base+mul*250+1] = X[:, base+250+mul*500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVG TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('datasets/avg_square_grad.csv').as_matrix()\n",
    "y = cvu.load_marks()[1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_l = y[:,0]\n",
    "y_f = y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, Y_l_tr, Y_f_tr, X_ts, Y_l_ts, Y_f_ts = cvu.random_sampling(X, y_l, y_f)\n",
    "#X_tr, X_ts, Y_l_tr, Y_f_tr, Y_l_ts, Y_f_ts = cvu.split_tr_ts(X, y_l, y_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0.01, 7, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIGHTNESS\n",
    "cvu.print_results('RLS',cvu.rlsCV_regression(alphas, X_tr, X_ts, Y_l_tr, Y_l_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRAGILITY\n",
    "cvu.print_results('RLS', cvu.rlsCV_regression(alphas, X_tr, X_ts, Y_f_tr, Y_f_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0.001, 1, 0.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIGHTNESS\n",
    "cvu.print_results('LASSO', cvu.lassoCV_regression(alphas, X_tr, X_ts, Y_l_tr, Y_l_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRAGILITY\n",
    "cvu.print_results('LASSO', cvu.lassoCV_regression(alphas, X_tr, X_ts, Y_f_tr, Y_f_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = {'alpha': list(np.arange(0.001, 1, 0.007))}\n",
    "kernel = 'rbf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIGHTNESS\n",
    "cvu.print_results('RIDGE KERNEL', cvu.ridgeKernelCV_regression(alphas, X_tr, X_ts, Y_l_tr, Y_l_ts, kernel=kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRAGILITY\n",
    "cvu.print_results('RIDGE KERNEL', cvu.ridgeKernelCV_regression(alphas, X_tr, X_ts, Y_f_tr, Y_f_ts, kernel=kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {'C':list(np.arange(1, 100, 10))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIGHTNESS\n",
    "cvu.print_results('SVM', cvu.svmCV_regression(c, X_tr, X_ts, Y_l_tr, Y_l_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRAGILITY\n",
    "cvu.print_results('SVM', cvu.svmCV_regression(c, X_tr, X_ts, Y_f_tr, Y_f_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ris = cvu.tree_regression(X_tr, X_ts, Y_f_tr, Y_f_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ris[0], ris[1])\n",
    "print(ris[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GROUP LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0.001, 1, 0.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "\n",
    "for i in range(30000):\n",
    "    groups.append([i*2, i*2+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Lightness\n",
    "coef, alpha = cvu.group_lassoCV(X_tr, Y_l_tr, alphas, groups, max_iter=cvu.MAX_ITER, rtol=1e-6)\n",
    "err = sum(abs(Y_l_ts-np.dot(X_ts, coef)))/len(Y_l_ts)\n",
    "var = np.var(abs(Y_l_ts-np.dot(X_ts, coef)))\n",
    "print(err)\n",
    "print(var)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fragility\n",
    "coef, alpha = cvu.group_lassoCV(X_tr, Y_f_tr, alphas, groups, max_iter=cvu.MAX_ITER, rtol=1e-6)\n",
    "err = sum(abs(Y_f_ts-np.dot(X_ts, coef)))\n",
    "var = np.var(abs(Y_f_ts-np.dot(X_ts, coef)))\n",
    "print(err)\n",
    "print(var)\n",
    "print(coef)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
